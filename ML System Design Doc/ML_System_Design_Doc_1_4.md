# ML System Design Doc - [RU]
## Дизайн ML системы - nanozymes_ai (MVP). вер.1.4 </h1>

Текущий этап разработки системы машинного обучения заключается в запуске сервиса в производственную среду. Разработка моделей для создания эмбеддингов успешно завершена, и их оптимизация проведена. Архитектура решения полностью спроектирована. Бизнес-требования к проекту четко сформулированы, а проблемное интервью с заинтересованными сторонами успешно проведено.

### 1. Цели и предпосылки
#### 1.1. Зачем идем в разработку продукта?
- Бизнес-цель `Product Owner`  Сократить  время ученых и инженеров на изучение больших текстов из доменной области 
   - Ученых-химиков на изучение статей - на 50%

- Почему станет лучше, чем сейчас, от использования ML `Product Owner` & `Data Scientist` Data Scientist 
  - В каждой статье от 10 до 50 страниц, на изучение одной статьи тратится до 4 часов. Разрабатываемый сервис должен позволять уменьшать это время до 2 часов за счет information retrieval текста.

- Что будем считать успехом итерации с точки зрения бизнеса `Product Owner` Сокращение до 2 часов времени на выделение из научных статей описания способа получения химического соединения.
  
#### 1.2. Бизнес-требования и ограничения
- Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями `Product Owner` 

Детальные бизнес-требования: [https://docs.google.com/document/d/1wzRkxla2tKxWpdSKJyNufT7vK5zfY5HU0-tbEOxiyjY/edit?usp=sharing](https://docs.google.com/document/d/1wzRkxla2tKxWpdSKJyNufT7vK5zfY5HU0-tbEOxiyjY/edit?usp=sharing) 

Создаем сервис, позволяющий в научных статьях выделять данные, отвечающие на вопрос пользователя. Например, сервис должен найти в тексте статьи инструкцию по синтезу химического вещества, информацию о каталитической активности и т.п.

Ограничения:

Нужно получать информацию только из содержимого научных статей, без подмешивания других данных. Это позволит сохранить достоверность ответа с научной точки зрения.

- Бизнес-ограничения `Product Owner`  Лучше, когда модель не находит нужных данных, чем когда находит их неверно.

- Что мы ожидаем от конкретной итерации `Product Owner`. Сервис может дать ответ на любой вопрос относительно любой статьи из базы данных https://dizyme.aicidlab.itmo.ru/database/
  
- Описание бизнес-процесса пилота, насколько это возможно - как именно мы будем использовать модель в существующем бизнес-процессе? `Product Owner`
  > - Срок тестирования - 2 дня.
  > - Группа тестирования - бизнес-заказчик и команда продукта.
  > - Тестирование UX согласно user case. После каждой итерации распознавания пользователь ставит субъективную оценку точности распознавания от 1 до 10.
  > - Будет протестировано не менее 10 статей.
   
- Что считаем успешным пилотом? Критерии успеха и возможные пути развития проекта `Product Owner`
  > - Количество субъективных оценок распознавания выше 5 баллов составляет не менее 75%.


#### 1.3. Что входит в скоуп проекта/итерации, что не входит
- На закрытие каких БТ подписываемся в данной итерации `Data Scientist`  Система распознавания заданного типа текста (параметры синтеза нанозимов) в научных статьях. 
- Что не будет закрыто `Data Scientist`  Сквозной поиск ответа на запрос по всем статьям из базы данных
- Описание результата с точки зрения качества кода и воспроизводимости решения `Data Scientist`
  
  Данные, загружаемые пользователем, будут **временно*** храниться в векторной базе данных.

  Для предикта текст статьи
  > - делится на фрагменты длиной N символов 
  > - фрагменты передаются модели multilingual-e5-large для построения эмбеддингов
  > - строится той же моделью эмбеддинг запроса пользователя
  > - выбирается k фрагментов текста, косинусное расстояние между эмбеддингом которыми и эмбеддингом запроса наименьшее
  > - к каждому из k фрагментов добавляется q фрагментов до и столько же после
  > - k таких наборов данныхв формате JSON по API передаются модели YandexGPT
  > - Возвращается ответ в формате JSON или .xml для отображения в области распознанного текста

- Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации) `Data Scientist` Извлечение числовых параметров, Расширение количества форматов документов для распознавания (epub, сканы документов). Классификация других типов статей (не по синтезу химических веществ). 
Проверка прав на использование контента при его загрузке

  
#### 1.4. Предпосылки решения
- Описание всех общих предпосылок решения, используемых в системе – с обоснованием от запроса бизнеса: какие блоки данных используем, горизонт прогноза, гранулярность модели, и др. `Data Scientist`
  Используем только тексты научных статей из базы данных

### 2. Методология Data Scientist
#### 2.1. Постановка задачи
- Что делаем с технической точки зрения `Data Scientist`  Извлечение данных из текста будет производиться на основе языковых моделей
Для извлечения эмбеддингов из фрагментов текста выбрана модель multilingual-e5-large. Критериями выбора являются качество и производительность. Сравнение производилось на лидерборде https://github.com/avidale/encodechka
Бейзлайн для оценки качества модели в текущем проекте - сравнение с качеством работы человека.
Целевые метрики работы модели:
1) Распознавание в тексте статьи описания. Precision - 90%
2) Полнота - количество правильно распознанных слов в описании. Recall - 80%.

- Блок-схема для бейзлайна и основного MVP с ключевыми этапами решения задачи: подготовка данных, построение прогнозных моделей, оптимизация, тестирование, закрытие технического долга, подготовка пилота, другое. `Data Scientist` 

Блок-схема решения (Часть 1: Схема работы сервиса)

![Схема работы сервиса](https://github.com/Rustemhak/nanozymes_ai/blob/main/ML%20System%20Design%20Doc/img/scheme–01.png)

Блок-схема решения (Часть 2: Этапы проекта)

![Этапы проекта](https://github.com/Rustemhak/nanozymes_ai/blob/main/ML%20System%20Design%20Doc/img/scheme–02.png)


#### 2.3. Этапы решения задачи `Data Scientist`  
- Данные собраны, размечены вручную: датасет со ссылками на статьи, с выделенными ответами на типовые запросы пользователей (см. вопросы для тестирования в бизнес-требованиях)

  #### Структура данных
  
| Наименование       | 
| ------------------ |
| Название статьи    |                                          
| Текст статьи       |     
| formula            |     
| activity           |     
| Syngony            |     
| length, nm         |     
| width, nm          |    
| depth, nm          |    
| surface            |      
| pol                |      
| surf               |      
| Mw(coat), g/mol    |      
| Km                 |      
| Vmax, mM           |      
| ReactionType       |     
| C min              |      
| C max              |      
| link               |     


- Построение моделей, тестирование, определение оптимальных параметров
  - Подготовка данных: деление текста на фрагменты. Это требуется для экономии токенов, отправляемых API OpenAI
    По результатам тестирования (параметры тестирования описаны в бизнес-требованиях) выбрана длина каждого фрагмента 100 символов
  - Построение эмбеддингов всех фрагментов текста и эмбеддинга запроса. Эмбеддинг запроса строится без его деления на фрагменты.
    Для извлечения эмбеддингов из фрагментов текста выбрана предобученная модель multilingual-e5-large. Критериями выбора являются качество и производительность Сравнение производилось на лидерборде https://github.com/avidale/encodechka
  - Для сравнения эмбеддингов выбрано косинусное расстояние - это стандарт в NLP. Определяется один ближайший к запросу фрагмент текста статьи 
  - Определение q фрагментов, примыкающих к ближайшему к запросу фрагменту текста статьи
    q фрагментов - состоит по результатам тестирования найдено оптимальное значение параметра q=20.
  - Отдаем модели для поиска ответа: запрос и k наборов из 20-1-20 фрагментов
    По результатам тестирования найдено оптимальное значение k=2


- Для тестирования использована выборка 10 случайных статей
- Демо заказчику, тестирование согласно сценариям, описанным в бизнес-требованиях https://docs.google.com/document/d/1wzRkxla2tKxWpdSKJyNufT7vK5zfY5HU0-tbEOxiyjY/edit?usp=sharing финальное определение параметров модели по результатам тестирования
 - Внедрение финальных значений параметров N, k, q в работу модели
- Внедрение моделей в промышленный контур - после настройки выделенного сервера с VPN - для отправки запроса модели OpenAI


### 3. Подготовка пилота  
  
#### 3.1. Способ оценки пилота  
- Краткое описание предполагаемого дизайна и способа оценки пилота Product Owner, Data Scientist with AB Group
  Порядок тестирования, критерии (метрики) успешности описаны в бизнес-требованиях https://docs.google.com/document/d/1wzRkxla2tKxWpdSKJyNufT7vK5zfY5HU0-tbEOxiyjY/

#### 3.3. Подготовка пилота  

- Data Scientist
  Для запуска пилота (после успешного прохождения тестирования) требуется 
- Наличие выделенного сервера с VPN для организации обращений к OpenAI
- Загрузка предрассчитанных эмбеддингов в базу данных со статьями


